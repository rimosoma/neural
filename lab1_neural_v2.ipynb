{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rimosoma/neural/blob/main/lab1_second_impl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgaqxrCBIHWO"
      },
      "source": [
        "# Digit recognition with a CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Machine Learning and Neural Networks\n",
        "\n",
        "Image classification with a CNN\n",
        "\n",
        "Lab duration: 3h\n",
        "\n",
        "Download the starting notebook from Portale della didattica (lab1.ipynb) and upload it to\n",
        "Google Colab.\n",
        "\n",
        "Exercise â€“ Handwritten digit recognition\n",
        "\n",
        "The MNIST dataset is composed of images of handwritten digits. There are 60000 training\n",
        "images and 10000 testing images. The images are grayscale with size 28 x 28. Labels\n",
        "identifying the true digit are also provided.\n",
        "A loader function is already provided. It returns the following tensors as numpy arrays:\n",
        "-  x_train: images to be used for training\n",
        "-  y_train: labels to be used for training (integers from 0 to 9)\n",
        "-  x_test: images to be used for testing\n",
        "-  y_test: labels to be used for testing (integers from 0 to 9)\n",
        "quindi **sparse_categorical**\n",
        "\n",
        "Fill the empty code cells of the notebook following the instructions. The final goal is to build\n",
        "a CNN that given a digit image predicts its value.\n",
        "The CNN is to be implemented as a **Keras Model** using the **Sequential Model**.\n",
        "The loss function is a softmax cross-entropy."
      ],
      "metadata": {
        "id": "4qykwuep_Arc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwPKXzBdsSai"
      },
      "source": [
        "Code to initiliaze Tensorflow 2.0 in Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RHeyqF6rev2"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "%load_ext tensorboard\n",
        "import datetime\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBmnWkSRslRb"
      },
      "source": [
        "**Import the MNIST dataset. The default loader will return tensors for the train/test partitions of the images and the labels.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aizfyvfms_nt"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train[:,:,:,np.newaxis]/255.0\n",
        "x_test = x_test[:,:,:,np.newaxis]/255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9TtiitutEm8"
      },
      "source": [
        "**[TODO] Check the size of the loaded tensors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlFW9kPUtpys"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(\"\\n\"\n",
        "    \"this is coherent because the images are 60000, they are 28x28 and thay are\"\n",
        "      \"\\ngrayscale so the channel is only one\"\n",
        "      \"\\n\"\n",
        "      \"\\nand in the y tensor instead are only saved 60000 scalars because it is needed\"\n",
        "      \"\\njust to store the labels of each image(index of the list)\")\n",
        "#print(x_train[0][1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riIKsGjMK2KT"
      },
      "source": [
        "**Prepare Keras callback for Tensorboard**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Grf-GiJFK-sS"
      },
      "source": [
        "logdir = \"logs/scalars/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "%tensorboard --logdir logs\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir, update_freq='batch')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVlXyF_8xGsW"
      },
      "source": [
        "**[TODO] Define a Keras Sequential model with the convolutional neural network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5C6JfgQNxf9P"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.Input(shape=(28, 28, 1)), # Recommended way to specify input shape\n",
        "\n",
        "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.ReLU(),\n",
        "    tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.ReLU(),\n",
        "    tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.ReLU(),\n",
        "    tf.keras.layers.GlobalAveragePooling2D(), # Convert 3D feature maps to 1D feature vectors\n",
        "    tf.keras.layers.Dense(10, activation='softmax') # Output layer for 10 classes\n",
        "])\n",
        "\n",
        "#sarebbe piu opportuno fare:\n",
        "#conv2d senza activation\n",
        "#layer di batch normalization\n",
        "#layer di relu, esiste proprio un layer apposta\n",
        "#tranne poi sull'ultimo layer in cui bisognerebbe fare:\n",
        "#layer global avarage pooling\n",
        "#full connected layer\n",
        "#come mostrato a slide 90"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5Arv2jyxgSz"
      },
      "source": [
        "**[TODO] Compile the Keras model: specify the optimization algorithm, the loss function and the test metric**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM9_th7SxlmM"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgY8SK7MxmBE"
      },
      "source": [
        "**[TODO] Train the Keras model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8-x6iwSxqqM"
      },
      "source": [
        "model.fit(x_train,y_train,batch_size=32,epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QhCHMnVFWv3"
      },
      "source": [
        "**[TODO] Print model summary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqTgD3xRFaJN"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uva5AeZrxrf0"
      },
      "source": [
        "**[TODO] Test the Keras model by computing the accuracy the whole test set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5536AAv7x1Al"
      },
      "source": [
        "model.evaluate(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJe4IZYfGxh9"
      },
      "source": [
        "**[TODO] Visualize test image number 47 and the prediction from the neural network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6233HLAIG98R"
      },
      "source": [
        "#Visualize test image number 47 and the prediction from the neural network\n",
        "plt.imshow(x_test[47].reshape(28,28),cmap='gray')\n",
        "false_new_value = x_test[47]\n",
        "prediction = model.predict(false_new_value.reshape(1,28,28,1))\n",
        "index_predict = np.argmax(prediction)\n",
        "print(\"the most probable prediction is:\",index_predict)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffyb1UCJMg6H"
      },
      "source": [
        "#Visualize test image number 44 and the prediction from the neural network\n",
        "plt.imshow(x_test[44].reshape(28,28),cmap='gray')\n",
        "false_new_value = x_test[44]\n",
        "prediction = model.predict(false_new_value.reshape(1,28,28,1))\n",
        "index_predict = np.argmax(prediction)\n",
        "print(\"the most probable prediction is:\",index_predict)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGjwq81LMtbR"
      },
      "source": [
        "#Visualize test image number 6 and the prediction from the neural network\n",
        "plt.imshow(x_test[6].reshape(28,28),cmap='gray')\n",
        "false_new_value = x_test[6]\n",
        "prediction = model.predict(false_new_value.reshape(1,28,28,1))\n",
        "index_predict = np.argmax(prediction)\n",
        "print(\"the most probable prediction is:\",index_predict)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
